{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDCdzSY3sRMC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from scipy.stats import skew\n",
        "\n",
        "pd.options.display.max_columns = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bfuX00VsRMD"
      },
      "source": [
        "Снова потренируемся в предсказании цен на недвижимость из [очередного датасета с каггла](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/)! В качестве основной метрики для валидации моделей будем использовать, как и ранее, `MSLE`.\n",
        "\n",
        "P.S. в данной домашней работе при построении любых моделей, использующих недетерменированные элементы (как бутстрап), в алгоритме указывайте параметр `random_state = 1` для воспроизводимости результатов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31MfJKJvsRMD"
      },
      "outputs": [],
      "source": [
        "df = (\n",
        "    pd.read_csv('data.csv')\n",
        "    .drop('Id', axis=1)\n",
        ")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq-lHWhbsRMD"
      },
      "outputs": [],
      "source": [
        "### Разделим выборку на объекты-таргеты\n",
        "\n",
        "y = df['SalePrice']\n",
        "X = df.drop(columns=['SalePrice'])\n",
        "\n",
        "### Логарифмируем таргет для будущей оптимизации\n",
        "### MSLE через MSE\n",
        "\n",
        "log_target = np.log1p(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLneBXIJsRMD"
      },
      "outputs": [],
      "source": [
        "### Это позволяет получить нормальное распределение таргета\n",
        "### Важно, например, для построения корректной\n",
        "### С точки зрения статистических свойств\n",
        "### Линейной модели.\n",
        "### Хотя здесь мы будем строить ансамбли деревьев,\n",
        "### И это не особо интересно.\n",
        "\n",
        "sns.set(rc={'figure.figsize':(15,10)})\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(y, bins=50)\n",
        "plt.title('Original Data')\n",
        "plt.xlabel('Sale Price')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.distplot(log_target, bins=50)\n",
        "plt.title('Natural Log of Data')\n",
        "plt.xlabel('Natural Log of Sale Price')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LHBG05jsRME"
      },
      "source": [
        "### В начале поработаем с пропусками!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caH47HYTsRME"
      },
      "source": [
        "Если в какой-либо колонке оказывается достаточно много пропусков, обычно советуют от них избавляться. Мотивировано это тем, что в таких фичах мы можем наблюдать серьезный недостаток информативности, а заполнение пропусков может лишь внести лишнего шума в данные.\n",
        "\n",
        "Избавьтесь от всех колонок, в которых пропусков оказывается больше 15%. (1б)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDJYUUvGsRME"
      },
      "outputs": [],
      "source": [
        "### Можно воспользоваться такой компактной конструкцией\n",
        "\n",
        "X = X.dropna(axis=1, thresh = 0.85*X.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fxvT_8ksRME"
      },
      "source": [
        "Вещественные колонки заполните медианным значением по фиче, а категориальные - самой популярной по колонке категорией. (2б)\n",
        "\n",
        "Заметьте, что колонки `MoSold`, `YrSold`, `GarageYrBlt`, `YearBuilt`, `YearRemodAdd` хоть в таблице не являются типами `object`, вряд ли их справедливо использовать как вещественные. Переведите все значения внутри в строки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-djSmTisRMF"
      },
      "outputs": [],
      "source": [
        "unwanted_num_cols = ['MoSold', 'YrSold', 'GarageYrBlt', 'YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "### Выделим категориальные фичи\n",
        "\n",
        "cat_cols = list(X.select_dtypes(include='object').columns)\n",
        "cat_cols += unwanted_num_cols\n",
        "\n",
        "X[cat_cols] = df[cat_cols].astype('object')\n",
        "\n",
        "### Выделим вещественные фичи\n",
        "\n",
        "num_cols = list(X.select_dtypes(exclude='object').columns)\n",
        "num_cols = [ele for ele in num_cols if ele not in unwanted_num_cols]\n",
        "\n",
        "### Заполним пропуски как и хотели!\n",
        "\n",
        "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
        "X[cat_cols] = X[cat_cols].fillna(X[cat_cols].mode().iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKMV97BrsRMF"
      },
      "outputs": [],
      "source": [
        "### Отложенная выборка\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    log_target,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq6pOczQsRMF"
      },
      "source": [
        "Напишите трансформер, который будет делать следующее:\n",
        "\n",
        "1. Масштабирование через StandardScaler для вещественных колонок\n",
        "2. Кодирование через OneHotEncoder для категориальных, содержащих менее, чем 5 уникальных значений\n",
        "3. Кодирование через TargetEncoder для всех остальных категориальных\n",
        "\n",
        "Для этого советуем воспользоваться библиотекой `category_encoders` помимо `sklearn`.\n",
        "\n",
        "А так же классом `ColumnTransformer` из `sklearn.compose`.\n",
        "\n",
        "P.S. Напомним, что для деревьев процедура StandardScaling не обязательна (решающие деревья нечувствительны к масштабу). Тем не менее, это может сделать обучение модели менее тяжелым (хранить большие числа сложно для задач с большим количеством данных)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYoC6U5osRMF"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from category_encoders import TargetEncoder\n",
        "from category_encoders.one_hot import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "cols_for_ohe = [x for x in cat_cols if X[x].nunique() < 5]\n",
        "cols_for_mte = [x for x in cat_cols if X[x].nunique() >= 5]\n",
        "\n",
        "cols_for_ohe_idx = [list(X.columns).index(col) for col in cols_for_ohe]\n",
        "cols_for_mte_idx = [list(X.columns).index(col) for col in cols_for_mte]\n",
        "numeric_cols_idx = [list(X.columns).index(col) for col in num_cols]\n",
        "\n",
        "t = [('OneHotEncoder', OneHotEncoder(), cols_for_ohe_idx),\n",
        "     ('MeanTargetEncoder', TargetEncoder(), cols_for_mte_idx),\n",
        "     ('StandardScaler', StandardScaler(), numeric_cols_idx)]\n",
        "\n",
        "col_transform = ColumnTransformer(transformers=t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VELMkgjksRMF"
      },
      "source": [
        "Посмотрите, как на наших данных справляется одно Решающее Дерево с дефолтными гиперпараметрами. Добавьте написанный ранее трансформер в модель. (1б)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN4fra8FsRMF"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipe_dt = Pipeline([(\"column_transformer\",\n",
        "                     col_transform),\n",
        "\n",
        "                    (\"decision_tree\",\n",
        "                     DecisionTreeRegressor())])\n",
        "\n",
        "pipe_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7w-EPRPsRMF"
      },
      "outputs": [],
      "source": [
        "train_preds = pipe_dt.predict(X_train)\n",
        "test_preds = pipe_dt.predict(X_test)\n",
        "\n",
        "train_error = np.mean((train_preds - y_train)**2)\n",
        "test_error = np.mean((test_preds - y_test)**2)\n",
        "\n",
        "\n",
        "print(f\"Качество на трейне: {train_error}\")\n",
        "print(f\"Качество на тесте: {test_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DFGppqwsRMG"
      },
      "source": [
        "Справляется даже без контроля переобучения!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIJ4-A4PsRMG"
      },
      "source": [
        "Посмотрим на перформанс Случайного Леса! Подберите параметры по отложенной выборке по данной сетке `param_grid`. Помните, что подбирать количество деревьев не супер обязательно, достаточно поставить их побольше. Что произошло с качеством модели по сравнению с одиноким деревом? (2б)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lvmm3kfsRMG"
      },
      "outputs": [],
      "source": [
        "np.random.seed = 1\n",
        "\n",
        "param_grid = {\n",
        "    \"random_forest__max_depth\": [10, 15, 20],\n",
        "    \"random_forest__min_samples_split\": [2, 5, 10],\n",
        "    \"random_forest__min_samples_leaf\": [1, 3, 5]\n",
        "}\n",
        "\n",
        "custom_cv = [(X_train.index.to_list(), X_test.index.to_list())]\n",
        "\n",
        "pipe_rf = Pipeline([(\"column_transformer\",\n",
        "                     col_transform),\n",
        "\n",
        "                    (\"random_forest\",\n",
        "                     RandomForestRegressor(random_state=1))])\n",
        "\n",
        "search = GridSearchCV(pipe_rf,\n",
        "                      param_grid,\n",
        "                      cv=custom_cv,\n",
        "                      scoring='neg_mean_squared_error',\n",
        "                      verbose=10)\n",
        "\n",
        "search.fit(X, log_target)\n",
        "\n",
        "print(f\"Best parameter (CV score={search.best_score_:.5f}):\")\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W93rE8nysRMG"
      },
      "source": [
        "Посмотрим на лучшие параметры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGEy4DVGsRMG"
      },
      "outputs": [],
      "source": [
        "search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeH93QeasRMG"
      },
      "outputs": [],
      "source": [
        "pipe_rf = Pipeline([(\"column_transformer\",\n",
        "                     col_transform),\n",
        "\n",
        "                    (\"random_forest\",\n",
        "                     RandomForestRegressor(max_depth=15,\n",
        "                                           min_samples_leaf=1,\n",
        "                                           min_samples_split=2,\n",
        "                                           random_state=1))])\n",
        "\n",
        "pipe_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4erhYepksRMG"
      },
      "outputs": [],
      "source": [
        "train_preds = pipe_rf.predict(X_train)\n",
        "test_preds = pipe_rf.predict(X_test)\n",
        "\n",
        "train_error = np.mean((train_preds - y_train)**2)\n",
        "test_error = np.mean((test_preds - y_test)**2)\n",
        "\n",
        "\n",
        "print(f\"Качество на трейне: {train_error}\")\n",
        "print(f\"Качество на тесте: {test_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR51PmRssRMG"
      },
      "source": [
        "Попробуем теперь поэкспериментировать с бэггингами.\n",
        "\n",
        "Постройте бэггинги с 100 базовыми моделями (и остальными стандартными параметрами) над линейной регрессией, деревом и случайным лесом (бэггинг над бэггингом!).\n",
        "\n",
        "Какое качество у каждой модели на тесте?\n",
        "\n",
        "Какой алгоритм получился лучше с точки зрения качества на тесте? (2б)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "yUvyB7cPsRMG"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "\n",
        "np.random.seed = 1\n",
        "results = []\n",
        "\n",
        "for regressor in [BaggingRegressor(LinearRegression(),\n",
        "                                   n_estimators=100,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=1),\n",
        "\n",
        "                  BaggingRegressor(RandomForestRegressor(),\n",
        "                                   n_estimators=100,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=1),\n",
        "\n",
        "                  BaggingRegressor(DecisionTreeRegressor(),\n",
        "                                   n_estimators=100,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=1)]:\n",
        "\n",
        "\n",
        "    pipe_bag = Pipeline([(\"column_transformer\",\n",
        "                          col_transform),\n",
        "\n",
        "                         (\"bagging\",\n",
        "                          regressor)])\n",
        "\n",
        "    pipe_bag.fit(X_train, y_train)\n",
        "\n",
        "    train_preds = pipe_bag.predict(X_train)\n",
        "    test_preds = pipe_bag.predict(X_test)\n",
        "\n",
        "    train_error = np.mean((train_preds - y_train)**2)\n",
        "    test_error = np.mean((test_preds - y_test)**2)\n",
        "\n",
        "    results.append([train_error, test_error])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXEFazAEsRMH"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BukJC9InsRMH"
      },
      "source": [
        "Улучшил ли бэггинг над Лесом качество по сравнению с одним Лесом с точки зрения как качества на тесте, так и на трейне. Как это можно объяснить? Как думаете, много ли смысла в использовании бэггинга над линейными моделями? Выбрали бы вы в данной ситуации именно их в качестве базовых?\n",
        "\n",
        "-- Строить бэггинг над лесом нет смысла, в силу того, что он в отдельности леса оказываются достаточно сильно коррелирующими\n",
        "\n",
        "-- Строить бэггинг над линейными моделями редко когда может дать хоть какой-то прирост в качестве, потому что линейная модель над линейными моделями - это все еще линейная модель. Но даже если строить нелинейную метамодель, то вступает в силу еще один аргумент - линейные модели обладат низким разбросом и слабо друг от друга отличаются, в построении линейной регрессии отсутствует случайность, поэтому, в целом, их выходы будут максимально близки друг к другу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKENmUuGsRMH"
      },
      "source": [
        "### Добавим новые фичи!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbfV6hPsRMH"
      },
      "source": [
        "Создайте следующие четыре новые вещественные фичи:\n",
        "\n",
        "1. Отношения площади 1 этажа к общей площади (колонки 1stFlrSF и GrLivArea, в %)\n",
        "2. Отношение Площади завершенного фундамента первого типа к общей площади фундамента (колонки BsmtFinSF1 и TotalBsmtSF, в %)\n",
        "3. Возраст дома (между YearBuilt и YrSold)\n",
        "4. Общая площадь самого дома и фундамента/цоколя (1stFlrSF + 2ndFlrSF + TotalBsmtSF)\n",
        "\n",
        "Обучите заново Случайный лес и найдите лучшие гиперпараметры на старой сетке.\n",
        "\n",
        "Улучшили ли качество модели новые фичи? (4б)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HQtGmhSsRMH"
      },
      "outputs": [],
      "source": [
        "### Реализация Функции для подсчета\n",
        "### Отношения площади 1 этажа к общей площади\n",
        "\n",
        "def floor_occupation(x):\n",
        "\n",
        "    if x[\"GrLivArea\"] == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return x[\"1stFlrSF\"] * 100 / x[\"GrLivArea\"]\n",
        "\n",
        "\n",
        "X_train[\"1stFlrPercent\"] = X_train.apply(\n",
        "    lambda x: floor_occupation(x), axis=1)\n",
        "\n",
        "X_test[\"1stFlrPercent\"] = X_test.apply(\n",
        "    lambda x: floor_occupation(x), axis=1)\n",
        "\n",
        "X[\"1stFlrPercent\"] = X.apply(\n",
        "    lambda x: floor_occupation(x), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSNm9xrpsRMH"
      },
      "outputs": [],
      "source": [
        "### Реализация Функции для подсчета отношения\n",
        "### Площади завершенного фундамента первого типа к общей площади фундамента\n",
        "\n",
        "\n",
        "def bsmt_finish(x):\n",
        "\n",
        "    if x[\"TotalBsmtSF\"] == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return x[\"BsmtFinSF1\"] * 100 / x[\"TotalBsmtSF\"]\n",
        "\n",
        "\n",
        "X_train[\"BsmtFinPercent\"] = X_train.apply(\n",
        "    lambda x: bsmt_finish(x), axis=1)\n",
        "\n",
        "X_test[\"BsmtFinPercent\"] = X_test.apply(\n",
        "    lambda x: bsmt_finish(x), axis=1)\n",
        "\n",
        "X[\"BsmtFinPercent\"] = X.apply(\n",
        "    lambda x: bsmt_finish(x), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw6XJ4nlsRMH"
      },
      "outputs": [],
      "source": [
        "### Реализация Функции для возраста\n",
        "\n",
        "\n",
        "def is_house_old(x):\n",
        "\n",
        "    return int(x['YrSold']) - int(x['YearBuilt'])\n",
        "\n",
        "\n",
        "X_train[\"HowOld\"] = X_train.apply(\n",
        "    lambda x: is_house_old(x), axis=1)\n",
        "\n",
        "X_test[\"HowOld\"] = X_test.apply(\n",
        "    lambda x: is_house_old(x), axis=1)\n",
        "\n",
        "X[\"HowOld\"] = X.apply(\n",
        "    lambda x: is_house_old(x), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWLAlzwjsRMH"
      },
      "outputs": [],
      "source": [
        "### Реализация Функции для общей площади\n",
        "\n",
        "\n",
        "def total_sq(x):\n",
        "\n",
        "     return x[\"1stFlrSF\"] + x[\"2ndFlrSF\"] + x['TotalBsmtSF']\n",
        "\n",
        "\n",
        "X_train[\"TotalSq\"] = X_train.apply(\n",
        "    lambda x: total_sq(x), axis=1)\n",
        "\n",
        "X_test[\"TotalSq\"] = X_test.apply(\n",
        "    lambda x: total_sq(x), axis=1)\n",
        "\n",
        "X[\"TotalSq\"] = X.apply(\n",
        "    lambda x: total_sq(x), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqwDzS00sRMH"
      },
      "outputs": [],
      "source": [
        "numeric_cols_idx = numeric_cols_idx + [X_test.shape[1]-i for i in range(1, 5)]\n",
        "\n",
        "t = [('OneHotEncoder', OneHotEncoder(), cols_for_ohe_idx),\n",
        "     ('MeanTargetEncoder', TargetEncoder(), cols_for_mte_idx),\n",
        "     ('StandardScaler', StandardScaler(), numeric_cols_idx)]\n",
        "\n",
        "col_transform = ColumnTransformer(transformers=t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4591MITjsRML"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"random_forest__max_depth\": [10, 15, 20],\n",
        "    \"random_forest__min_samples_split\": [2, 5, 10],\n",
        "    \"random_forest__min_samples_leaf\": [1, 3, 5]\n",
        "}\n",
        "\n",
        "pipe_rf = Pipeline([(\"column_transformer\",\n",
        "                     col_transform),\n",
        "\n",
        "                    (\"random_forest\",\n",
        "                     RandomForestRegressor(random_state=1))])\n",
        "\n",
        "search = GridSearchCV(pipe_rf,\n",
        "                      param_grid,\n",
        "                      cv=custom_cv,\n",
        "                      scoring='neg_mean_squared_error',\n",
        "                      verbose=10)\n",
        "\n",
        "search.fit(X, log_target)\n",
        "\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2EDqGI0sRMM"
      },
      "outputs": [],
      "source": [
        "pipe_rf = Pipeline([(\"column_transformer\",\n",
        "                     col_transform),\n",
        "\n",
        "                    (\"random_forest\",\n",
        "                     RandomForestRegressor(max_depth=20,\n",
        "                                           min_samples_leaf=1,\n",
        "                                           min_samples_split=2))])\n",
        "\n",
        "pipe_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqAka6FYsRMM"
      },
      "outputs": [],
      "source": [
        "train_preds = pipe_rf.predict(X_train)\n",
        "test_preds = pipe_rf.predict(X_test)\n",
        "\n",
        "train_error = np.mean((train_preds - y_train)**2)\n",
        "test_error = np.mean((test_preds - y_test)**2)\n",
        "\n",
        "\n",
        "print(f\"Качество на трейне: {train_error}\")\n",
        "print(f\"Качество на тесте: {test_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G4prgbKsRMM"
      },
      "source": [
        "-- Новые фичи немного помогли!"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}